\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{socinf}
\citation{rrmf}
\citation{sr}
\citation{Noel2012NOF}
\citation{lla}
\citation{ste}
\citation{sorec}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{\thepage }{section.1}}
\newlabel{sec:introduction}{{1}{\thepage }{Introduction\relax }{section.1}{}}
\citation{saez2011high}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of \emph  {social affinity filtering (SAF)}: A \emph  {social affinity group (SAG)} of user $u$ (ego) consists of a set of alternate users $\{ v \}$ (alters) who have a certain \emph  {interaction} or share an \emph  {activity} membership with $u$. SAF learns to classify whether user $u$ will like item $i$ based on the observed preferences of members of each SAG of user $u$ toward item $i$.\relax }}{\thepage }{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:overview}{{1}{\thepage }{Overview of \emph {social affinity filtering (SAF)}: A \emph {social affinity group (SAG)} of user $u$ (ego) consists of a set of alternate users $\{ v \}$ (alters) who have a certain \emph {interaction} or share an \emph {activity} membership with $u$. SAF learns to classify whether user $u$ will like item $i$ based on the observed preferences of members of each SAG of user $u$ toward item $i$.\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Social Affinity Filtering}{\thepage }{section.2}}
\newlabel{sec:methodology}{{2}{\thepage }{Social Affinity Filtering\relax }{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Interactions and Activities on Facebook}{\thepage }{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Social Affinity Groups (SAGs)}{\thepage }{subsection.2.2}}
\newlabel{ssec:sag}{{2.2}{\thepage }{Social Affinity Groups (SAGs)\relax }{subsection.2.2}{}}
\newlabel{fn:fbblog}{{1}{\thepage }{\relax }{Hfootnote.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Social Affinity Filtering (SAF)}{\thepage }{subsection.2.3}}
\newlabel{ssec:SAfeature}{{2.3}{\thepage }{Social Affinity Filtering (SAF)\relax }{subsection.2.3}{}}
\citation{newsweeder}
\citation{socinf}
\citation{rrmf}
\citation{ste}
\citation{sorec}
\citation{sr}
\citation{Noel2012NOF}
\citation{lla}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SAF training data example: each row corresponds to a training data sample for a specific user-item pair $(u,i)$ for which the prediction target $\mathit  {likes}(u,i)$ is observed (last column). All other columns represent the value of ISAF or ASAF features evaluated relative to the $(u,i)$ label of each row. All columns are binary-valued ($0=\mathit  {false},1=\mathit  {true}$).\relax }}{\thepage }{figure.caption.6}}
\newlabel{fig:features_overview}{{2}{\thepage }{SAF training data example: each row corresponds to a training data sample for a specific user-item pair $(u,i)$ for which the prediction target $\like (u,i)$ is observed (last column). All other columns represent the value of ISAF or ASAF features evaluated relative to the $(u,i)$ label of each row. All columns are binary-valued ($0=\false ,1=\true $).\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}SAF vs. Other Filtering Methods}{\thepage }{subsection.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces App user demographics. The \emph  {ego network} is the friend network of the App users.\relax }}{\thepage }{table.caption.7}}
\newlabel{tab:demographics}{{1}{\thepage }{App user demographics. The \emph {ego network} is the friend network of the App users.\relax \relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Statistics on user {\em  interactions}. \relax }}{\thepage }{table.caption.8}}
\newlabel{tab:interactions}{{2}{\thepage }{Statistics on user {\em interactions}. \relax \relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Statistics on user {\em  actions}, counted for {\em  Groups, Pages} and {\em  Favourites} over the App users and their ego network.\relax }}{\thepage }{table.caption.9}}
\newlabel{tab:interests}{{3}{\thepage }{Statistics on user {\em actions}, counted for {\em Groups, Pages} and {\em Favourites} over the App users and their ego network.\relax \relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Evaluation}{\thepage }{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Description}{\thepage }{subsection.3.1}}
\newlabel{sec:datadesc}{{3.1}{\thepage }{Data Description\relax }{subsection.3.1}{}}
\citation{bellkor}
\citation{pmf}
\citation{Noel2012NOF}
\citation{liblinear}
\citation{Noel2012NOF}
\citation{socinf}
\citation{rrmf}
\citation{ste}
\citation{sorec}
\citation{sr}
\citation{Noel2012NOF}
\citation{lla}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Dataset breakdown of prediction target $like(u,i)$ by the source of the link (Friend/Non-friend) and rating (Like=$\mathit  {true}$, Dislike=$\mathit  {false}$).\relax }}{\thepage }{table.caption.10}}
\newlabel{tab:likeinfo}{{4}{\thepage }{Dataset breakdown of prediction target $like(u,i)$ by the source of the link (Friend/Non-friend) and rating (Like=$\true $, Dislike=$\false $).\relax \relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}SAF Comparison}{\thepage }{subsection.3.2}}
\newlabel{sec:saf_analysis}{{3.2}{\thepage }{SAF Comparison\relax }{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Cold-start Evaluation}{\thepage }{subsection.3.3}}
\newlabel{sec:coldstart_analysis}{{3.3}{\thepage }{Cold-start Evaluation\relax }{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparision of a simple baseline (Const), two collaborative filtering baselines (NN and MF), a social collaborative filtering baseline (SMB) and novel SAF recommenders using different feature sets (one ISAF and three ASAF sets) and classifiers (NB,LR,SVM). The best SAF-based model (LR-ASAF) --- for Page likes --- significantly outperforms all baselines by at least 6\%. Combining all four feature sets (not shown) does not lead to improvement over Page likes features alone.\relax }}{\thepage }{figure.caption.11}}
\newlabel{Fig1}{{3}{\thepage }{Comparision of a simple baseline (Const), two collaborative filtering baselines (NN and MF), a social collaborative filtering baseline (SMB) and novel SAF recommenders using different feature sets (one ISAF and three ASAF sets) and classifiers (NB,LR,SVM). The best SAF-based model (LR-ASAF) --- for Page likes --- significantly outperforms all baselines by at least 6\%. Combining all four feature sets (not shown) does not lead to improvement over Page likes features alone.\relax \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cold-start evaluation of SAF: accuracy evaluated on cold-start users outperforms the most likely class (Constant) predictor baseline and is somewhat comparable to the non cold-start case when all test user data is \emph  {not} withheld from training.\relax }}{\thepage }{figure.caption.12}}
\newlabel{fig:coldstart}{{4}{\thepage }{Cold-start evaluation of SAF: accuracy evaluated on cold-start users outperforms the most likely class (Constant) predictor baseline and is somewhat comparable to the non cold-start case when all test user data is \emph {not} withheld from training.\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Interaction Analysis}{\thepage }{subsection.3.4}}
\newlabel{sec:interaction_analysis}{{3.4}{\thepage }{Interaction Analysis\relax }{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Conditional Entropy of modalities/activities for incoming/outgoing interactions vs. item liked by at least $k$ friends. Increasing $k$ generally has a stronger influence on informativeness than other features of interaction SAGs.\relax }}{\thepage }{figure.caption.14}}
\newlabel{Fig2}{{5}{\thepage }{Conditional Entropy of modalities/activities for incoming/outgoing interactions vs. item liked by at least $k$ friends. Increasing $k$ generally has a stronger influence on informativeness than other features of interaction SAGs.\relax \relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Conditional entropy of various interactions (lower conditional entropies are more informative). We observe that interactions on videos are more informative than other modalities (link, post, photo), tagging is marginally more informative than commenting and liking, and outgoing interactions are slightly more informative than incoming ones. Breaking down the analysis by modality-direction and action-direction reveals finer-grained distinctions.\relax }}{\thepage }{table.caption.13}}
\newlabel{table:ce_interaction}{{5}{\thepage }{Conditional entropy of various interactions (lower conditional entropies are more informative). We observe that interactions on videos are more informative than other modalities (link, post, photo), tagging is marginally more informative than commenting and liking, and outgoing interactions are slightly more informative than incoming ones. Breaking down the analysis by modality-direction and action-direction reveals finer-grained distinctions.\relax \relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Activity Analysis}{\thepage }{subsection.3.5}}
\newlabel{sec:activity_analysis}{{3.5}{\thepage }{Activity Analysis\relax }{subsection.3.5}{}}
\citation{Chang2010ethnicity}
\citation{backstrom2011center}
\citation{backstrom2011center}
\citation{wilson2009user}
\citation{hill2003social}
\citation{backstrom2011center}
\citation{Golub2010selectionbiase}
\citation{ver2011stops}
\citation{Romero2011hashtag}
\citation{asur2011trends}
\citation{Bakshy2011everyone}
\citation{Bakshy2012chamber}
\citation{Bakshy2011everyone}
\citation{asur2011trends}
\citation{Bakshy2011everyone}
\citation{influence}
\citation{Bakshy2012chamber}
\citation{Goel2012structure}
\citation{saez2011high}
\citation{singla2008yes}
\citation{Anderson2012}
\citation{brandtzag2011facebook}
\citation{gilbert2009predicting}
\citation{koren2009matrix}
\citation{sorec}
\citation{sr}
\citation{rrmf}
\citation{tf}
\citation{Jiang2012SRA}
\citation{Jiang2012SCR}
\citation{lla}
\citation{ste}
\citation{sorec}
\citation{Noel2012NOF}
\@writefile{toc}{\contentsline {section}{\numberline {4}Related Work}{\thepage }{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Conditional entropy vs. size (a); logistic regression feature weights vs size (b). In (a) we observe that the large membership ASAGs are rarely informative while the most informative SAGs tend to have low memberships. Similarly in (b) we see that the most predictive features with the largest weights (positive or negative) are concentrated toward small ASAGs. \relax }}{\thepage }{figure.caption.16}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces Fig:}}{\thepage }{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces Fig:}}{\thepage }{subfigure.6.2}}
\newlabel{Fig3}{{6}{\thepage }{Conditional entropy vs. size (a); logistic regression feature weights vs size (b). In (a) we observe that the large membership ASAGs are rarely informative while the most informative SAGs tend to have low memberships. Similarly in (b) we see that the most predictive features with the largest weights (positive or negative) are concentrated toward small ASAGs. \relax \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Average conditional entropy of top 10\% groups, pages and favourite features \emph  {cumulative} over the size. Here we see that as we add in larger membership ASAGs, the average informativeness decreases substantially (entropy increases).\relax }}{\thepage }{figure.caption.17}}
\newlabel{Fig4}{{7}{\thepage }{Average conditional entropy of top 10\% groups, pages and favourite features \emph {cumulative} over the size. Here we see that as we add in larger membership ASAGs, the average informativeness decreases substantially (entropy increases).\relax \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Conditional entropy for top 1000 favourites breakdown by categories. While at least half of ASAG categories with many options like music are not informative (judging by median values), some of the most informative ASAGs are music. This reiterates the point that it is crucial to \emph  {learn} which ASAGs are informative rather than aggregating average information.\relax }}{\thepage }{figure.caption.18}}
\newlabel{Fig5}{{8}{\thepage }{Conditional entropy for top 1000 favourites breakdown by categories. While at least half of ASAG categories with many options like music are not informative (judging by median values), some of the most informative ASAGs are music. This reiterates the point that it is crucial to \emph {learn} which ASAGs are informative rather than aggregating average information.\relax \relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces (top) Examples of 8 items per Favourite category near the \emph  {median} conditional entropy (\emph  {median informativeness}). (bottom) Examples of top 8 items with the lowest conditional entropy (\emph  {most informative}). A general trend is that more informative favourite category ASAGs tend to be more specialised in appeal, e.g. ``Avascular Necrosis'' is an informative music group favourite --- its members tend to share common preferences --- while ``John Lennon'' and ``U2'' have a broader audience with more diverse preferences. Interestingly, ''Sherlock'' appears in both most and median informative table but the median informative is an official page with wide range of fans, whereas the most informative is a duplicate fan page with few fans.\relax }}{\thepage }{table.caption.15}}
\newlabel{table:fav_examples}{{6}{\thepage }{(top) Examples of 8 items per Favourite category near the \emph {median} conditional entropy (\emph {median informativeness}). (bottom) Examples of top 8 items with the lowest conditional entropy (\emph {most informative}). A general trend is that more informative favourite category ASAGs tend to be more specialised in appeal, e.g. ``Avascular Necrosis'' is an informative music group favourite --- its members tend to share common preferences --- while ``John Lennon'' and ``U2'' have a broader audience with more diverse preferences. Interestingly, ''Sherlock'' appears in both most and median informative table but the median informative is an official page with wide range of fans, whereas the most informative is a duplicate fan page with few fans.\relax \relax }{table.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Accuracy of the SAF increases as users become more active in social network by joining more groups/pages/favourites. It does not appear too many activities hurts --- SAF learns to discriminate when activities are predctive.\relax }}{\thepage }{figure.caption.19}}
\newlabel{AccuracyVsmembership}{{9}{\thepage }{Accuracy of the SAF increases as users become more active in social network by joining more groups/pages/favourites. It does not appear too many activities hurts --- SAF learns to discriminate when activities are predctive.\relax \relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Accuracy increases as the number of active features increases, but then, after reaching a certain limit, it starts to decrease, i.e., excessive item popularity among activities hurts the discriminative power of SAF to make good recommendations.\relax }}{\thepage }{figure.caption.20}}
\newlabel{fig:AccuracyVsactiveFeats}{{10}{\thepage }{Accuracy increases as the number of active features increases, but then, after reaching a certain limit, it starts to decrease, i.e., excessive item popularity among activities hurts the discriminative power of SAF to make good recommendations.\relax \relax }{figure.caption.20}{}}
\bibdata{bibliography}
\bibcite{Anderson2012}{1}
\bibcite{asur2011trends}{2}
\bibcite{backstrom2011center}{3}
\bibcite{Bakshy2011everyone}{4}
\bibcite{Bakshy2012chamber}{5}
\bibcite{bellkor}{6}
\bibcite{brandtzag2011facebook}{7}
\bibcite{Chang2010ethnicity}{8}
\bibcite{socinf}{9}
\bibcite{liblinear}{10}
\bibcite{gilbert2009predicting}{11}
\bibcite{Goel2012structure}{12}
\bibcite{Golub2010selectionbiase}{13}
\bibcite{hill2003social}{14}
\bibcite{Jiang2012SCR}{15}
\bibcite{Jiang2012SRA}{16}
\bibcite{koren2009matrix}{17}
\bibcite{newsweeder}{18}
\bibcite{rrmf}{19}
\bibcite{ste}{20}
\bibcite{sorec}{21}
\bibcite{sr}{22}
\bibcite{Noel2012NOF}{23}
\bibcite{tf}{24}
\bibcite{Romero2011hashtag}{25}
\bibcite{saez2011high}{26}
\bibcite{pmf}{27}
\bibcite{singla2008yes}{28}
\bibcite{ver2011stops}{29}
\bibcite{influence}{30}
\bibcite{wilson2009user}{31}
\bibcite{lla}{32}
\bibstyle{abbrv}
\@writefile{toc}{\contentsline {section}{\numberline {5}Future Work}{\thepage }{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Acknowledgements}{\thepage }{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{\thepage }{section.7}}
