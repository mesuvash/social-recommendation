%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}

\title{
New Objective Functions for Social Collaborative Filtering
%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Joseph Noel         \and
        Scott Sanner %etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Joseph Noel \at
              Level 5, 13 Garden Street, NSW, Australia. \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{joseph.noel@nicta.com.au}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           Scott Sanner \at
            7 London Circuit,  Canberra, ACT, Australia. \\
            Tel.: +123-45-678910\\
            Fax: +123-45-678910\\
            \email{scott.sanner@nicta.com.au}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
\keywords{First keyword \and Second keyword \and More}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{intro}
Your text comes here. Separate text sections with

\section{Experiments}
\label{sec:1}
Text with citations \cite{RefB} and \cite{RefJ}.

\subsection{Experiment 1}
\label{sec:2}

%as required. Don't forget to give each section
%and subsection a unique label (see Sect.~\ref{sec:1}).


For the first experiment, we evaluated each algorithm using 10-fold cross validation by training and testing on only ACTIVE data. Objectives for each algorithm were optimized via gradient descent.
$\lambda$'s for the matrix factorization based algorithms were tuned prior to the start of the trial by a systematic line (grid) search over $10^n$ for $n \in \{-10, -9, ..., 10\}$ to maximize 
accretion on 10\% held-out data, training on the other 90\%. This was repeated for $K \in \{3, 5, 7, 10, 15, 20, 30\}$ to find the best $K$. $N$ and $C$ were tuned similarly via line search 
over $N \in \{1, 2,..., 250\}$ and $C \in [2^{-15}, 2^{15}]$.

\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
FIW & 0.7507 &  0.8208 & 0.5335 &  0.6467  \\
FUW & 0.4274 & 0.4274  & 1.0  & 0.5989 \\
Global &  0.4274 & 0.4274  & 1.0  & 0.5989 \\
Hybrid &  0.7140 & 0.6722 & 0.6607 & 0.6615  \\
Logistic Regression &  0.7196  & 0.6869 & 0.6335  & 0.6590 \\
Matchbox & 0.6243 & 0.6103 & 0.3367 & 0.4338 \\
NN & 0.4274 & 0.4274  & 1.0  & 0.5989 \\
Soc. Hybrid & 0.7228 & 0.6969  & 0.6307  & 0.6597  \\
Soc. Matchbox & 0.6253 & 0.6151  & 0.3339 & 0.4325  \\
Spec. Copreference & 0.6297  & 0.6240 & 0.3392  & 0.4392 \\
SVM & 0.6779 & 0.6093 & 0.7897  & 0.6811 \\
Spec. Matchbox & 0.6338  & 0.6310 & 0.3466 & 0.4471  \\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}




\subsection{Experiment 2}
\label{sec:2}

For the 2nd experiment, we wanted to see whether including PASSIVE data improves on the results over using solely ACTIVE data.
To test this, we evaluated the algorithms by training them on UNION data and testing on ACTIVE data. The train/test split over the ACTIVE data is exactly
the same as in Experiment 1, but this time we supplement each training with additional PASSIVE data. The PASSIVE data used are all the 
links that were "liked" by the users on Facebook. The hyper parameters were tuned as in Experiment 1.


\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
FUW &  0.4274 & 0.4274  & 1.0000 & 0.5989 \\
FIW & 0.4206  & 0.4235 & 0.9840 & 0.5922  \\
Global & 0.4274 & 0.4274  & 1.0000 & 0.5989 \\
Hybrid & 0.6989 & 0.6213 & 0.7590 & 0.6831 \\
LogisticRegression & 0.7030 & 0.6244 & 0.7674 & 0.6883 \\
Matchbox & 0.6225  & 0.5932 & 0.3787  & 0.4612 \\
NN & 0.4274 & 0.4274  & 1.0000 & 0.5989 \\
Soc. Hybrid & 0.7055 & 0.6239 & 0.7855 & 0.6952 \\
Soc. Matchbox & 0.6243 & 0.6204  & 0.3148  & 0.4171 \\
Spec. Copreference & 0.62598 & 0.6117 & 0.3448  & 0.4408  \\
Spec. Matchbox & 0.6238 & 0.6043  & 0.3508  & 0.4437 \\
SVM & 0.6912 & 0.6145 & 0.7586 & 0.6772  \\
\noalign{\smallskip}\hline
 \end{tabular} 
\end{table}

Again, Soc. Hybrid was the best performing accuracy. However, most algorithms performed worse with the addition of PASSIVE data during training than with just using ACTIVE data. This suggests that the "likes" on the PASSIVE data aren't as informative of the user's preferences than the explicit "likes" and "dislikes" in the ACTIVE data.

\subsection{Experiment 3}
\label{sec:2}

For Experiment 3,  we wanted to check weather the addition of user ad item features actually helps with the performance of the algorithms, over just using the latent features in matrix factorization. We repeated the same experiments as in Experiment 1 for Matchbox and Soc. Matchbox, but removed the user and item features. Matchbox hence basically becomes the PMF algorithm described in Salakhutdinov and Mnih.


\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
Matchbox & 0.6243 & 0.6103 & 0.3367& 0.4338 \\
Matchbox (No Features) & 0.6175  & 0.6366  & 0.2512& 0.3582 \\

Soc. Matchbox  & 0.6238 & 0.6235  & 0.3024  & 0.4070  \\
{\bf Social Matchbox (No Features)} & {\bf 0.6149} & {\bf 0.6391} & {\bf 0.2272} &  {\bf 0.3344} \\

\noalign{\smallskip}\hline
 \end{tabular} 
\end{table}

\subsection{Experiment 4}
\label{sec:2}

For the next experiment, we wanted to reevaluate the algorithms again in the same manner as in Experiment 1, but using Macro Averaging when calculating the metric.


\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
Global &  0.4396 & 0.4396 & 1.0000 & 0.5840 \\
FUW &  0.4396 & 0.4396 & 1.0000 & 0.5840 \\
FIW & 0.7911 & 0.5737 & 0.6382 & 0.5970 \\
Hybrid & 0.7059 & 0.5252 & 0.5505 & 0.5112 \\
Matchbox & 0.6145 &  0.4735 & 0.3104 & 0.3523 \\
SocialHybrid & 0.7134  & 0.4773 & 0.4902 & 0.4545 \\
SocialMatchbox & 0.6157 & 0.4640 & 0.2896 & 0.3360 \\
SpectralCopreference & 0.6248 & 0.4865 & 0.3096 & 0.3568 \\
SpectralMatchbox & 0.62557 &0.4994 & 0.3250 & 0.3686 \\
LogisticRegression & 0.7175 & 0.4916 & 0.4868 & 0.4527 \\
NN & 0.4396 & 0.4396 & 1.0000 & 0.5840 \\

SVM & 0.6702 & 0.5264 & 0.7347 & 0.5932 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}
 

\subsection{Experiment 5}
\label{sec:2}

For Experiment 5, we tested the Social Matchbox and Spectral Matchbox algorithms using different ways of normalizing the Social Interaction measure between the two users. 

MaxNormalizationNoLog
\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
 \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6280 & 0.6346 & 0.3070 & 0.4137 \\
SpectralMatchbox & 0.6353 & 0.6342 & 0.3487 & 0.4497 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

MaxNormalizationWithLog
\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6255 & 0.6169 & 0.3307 & 0.4301 \\
SpectralMatchbox & 0.6231 & 0.6101 & 0.3289 & 0.4270 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

MaxNormalizationWithLogPlus1
\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
 & Accuracy & Precision & Recall & F1 \\
 \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6261 & 0.6186 & 0.3293 & 0.4294 \\
SpectralMatchbox & 0.6345 & 0.6321& 0.3487 & 0.4492 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

MeanNormalizationNoLog
\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
Algorithm & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6274 & 0.6310 & 0.3120 & 0.4171 \\
SpectralMatchbox & 0.6373 & 0.6351 & 0.3565 & 0.4563 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

MeanNormalizationWithLog
\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
Algorithm & Accuracy & Precision & Recall & F1 \\
 \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6238 & 0.6235 & 0.3024 & 0.4070 \\
SpectralMatchbox & 0.6231 & 0.6103 & 0.3314 & 0.4293 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

MeanNormalizationWithLogPlus1
\begin{table}
\begin{tabular}{l  c  c  c  c }
\hline\noalign{\smallskip}
Algorithm & Accuracy & Precision & Recall & F1 \\
  \noalign{\smallskip}\hline\noalign{\smallskip}
SocialMatchbox & 0.6261 & 0.6198 & 0.3240 & 0.4252 \\
SpectralMatchbox & 0.6338 & 0.6310 &  0.3466 & 0.4471 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}


\subsection{Experiment 6}
\label{sec:2}

For the last experiment, we simulated the cold-start problem by giving each algorithm more $25\%$ more training data for each user. We wanted to see if the additional training data helps improve the training. Aside from the additional training data, the experimental setup is the same as in Experiment 1.

\begin{table}
\begin{tabular}{ l  c  c  c  c }
\hline\noalign{\smallskip}
Algorithm & Accuracy & Precision & Recall & F1 \\
 \noalign{\smallskip}\hline\noalign{\smallskip}
Global & 0.4028 & 0.4028 & 1.0000 & 0.5724 \\
FUW & 0.4028 & 0.4028 & 1.0000 & 0.5724 \\
FIW & 0.8179 & 0.8330 & 0.0.6976 & 0.7502 \\
Hybrid & 0.7127 & 0.6647 & 0.5481 & 0.5992 \\
LogisticRegression & 0.7280 & 0.6694 & 0.6249 & 0.6448 \\
Matchbox & 0.6149 & 0.5323 & 0.2951 & 0.3778 \\
NN & 0.4028 & 0.4028 & 1.0000 & 0.5724 \\
SocialHybrid & 0.7317 & 0.6952 & 0.5615 & 0.6118 \\
SocialMatchbox & 0.6265 & 0.5594 & 0.3081 & 0.3958 \\
SpectralCopreference & 0.6265 & 0.5616 & 0.3051 & 0.3938 \\
Spectral Matxhbox & 0.6370 & 0.5917 & 0.3288 & 0.4194 \\

SVM & 0.7274 & 0.6490 & 0.7041 & 0.6705 \\
\noalign{\smallskip}\hline
\end{tabular} 
\end{table}

\paragraph{Paragraph headings} Use paragraph headings as needed.
\begin{equation}
a^2+b^2=c^2
\end{equation}

% For one-column wide figures use
\begin{figure}
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics{example.eps}
% figure caption is below the figure
\caption{Please write your figure caption here}
\label{fig:1}       % Give a unique label
\end{figure}
%
% For two-column wide figures use
\begin{figure*}
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[width=0.75\textwidth]{example.eps}
% figure caption is below the figure
\caption{Please write your figure caption here}
\label{fig:2}       % Give a unique label
\end{figure*}
%
% For tables use
\begin{table}
% table caption is above the table
\caption{Please write your table caption here}
\label{tab:1}       % Give a unique label
% For LaTeX tables use
\begin{tabular}{lll}
\hline\noalign{\smallskip}
first & second & third  \\
\noalign{\smallskip}\hline\noalign{\smallskip}
number & number & number \\
number & number & number \\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}


%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
\begin{thebibliography}{}
%
% and use \bibitem to create references. Consult the Instructions
% for authors for reference list style.
%
\bibitem{RefJ}
% Format for Journal Reference
Author, Article title, Journal, Volume, page numbers (year)
% Format for books
\bibitem{RefB}
Author, Book title, page numbers. Publisher, place (year)
% etc
\end{thebibliography}

\end{document}
% end of file template.tex

