%%
%% Template chap2.tex
%%


others have pointed out non social more important and we observe that too
interactions give implicit networks of friendshipsprevious methods say if people interact alot then they will like the same things, 
we break it down into smaller implicit overlap of preferences

\chapter{Interactions}
\label{cha:interactions}

stronger affinity for what people say to you

This chapter is dedicated to analysing the different \emph{user interaction} features present in Facebook.

The \emph{user interactions} we examine in this thesis can be broken down into two distinct groups, interactions between users and messages 
sent between users.

bias for incoming having a stronger affinity

interaction filtering cant help when interactions dont exist - as soon as interactions we can exploit the information

\section{User Interactions}
\label{sec:inter}

There are a number of potential interaction mediums between users under the Facebook paradigm. These can be summarised into the following 
categories.

\begin{itemize}
\item \textbf{Direction}: The manner an interaction is received, either \emph{Incoming} where a message is posted to some user or 
\emph{Outgoing} where some user posts a message to another user. Interaction directionality has been shown to be highly 
reflective of user preferences ~\cite{saez2011high}.
\item \textbf{Modality}: The medium some user employs to interact with another user via either \emph{Links}, \emph{Posts}, \emph{Photos} or \emph{Videos}.
\item \textbf{Type}: The style some user employs to interact with another user via either \emph{Comment}, \emph{Tag} or \emph{Like}.
\end{itemize}

In this case, the $I$ for out feature vector $X$ is defined as the cross product of the above components where:
\[ I = \{Incoming, Outgoing\} \times \{Posts,Photos,Videos,Links\} \times \{Comments,Tags,Likes\} \]

The alters of $I$ can then be defined as all users who have interacted with or been interacted with the current user via some $i$. 
Each component of $I$ is set to $1$ if any of the alters defined by the current set $i$ have also liked the current item $M$, otherwise 
it is set to $0$.

Applying the feature vector described above to our classification algorithms we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/bar_interactions.pdf}
		\caption{Accuracy results using \emph{user interaction} features. Against all data \emph{user interactions} do not outperform our baselines.}
	\end{center}
\end{figure}

\emph{User Interactions} are marginally outperformed by our SMB baseline, showing that relatively \emph{User Interactions} do not 
improve upon classification.

One reason for this result could be we can not track information passing outside of Facebook, users who frequently interact could be real 
world friends and hence share information via email or word of mouth and not over Facebook.

\clearpage

Comparing \emph{User Interactions} against our exposure curve we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/line_interactions.pdf}
		\caption{Accuracy results against exposure using \emph{user interaction} features. \emph{User interactions} provide a drastic improvement 
		over our baselines as $k$ increases, suggesting SMB is not always the best classifier.}
	\end{center}
\end{figure}

We glean that as our data is restricted, the performance of our classifiers improves (note LR and SVM obtained the same results in this graph) 
over time. This graph shows that for \emph{User Interactions} having one user liking an item is enough to improve upon our baselines classifiers.

\section{Conversation}
\label{sec:groups}

Given the nature of Facebook, it is possible for users to post or receive messages from other users.

These messages can be broken down based on their directionality, either \emph{Outgoing} which are words sent to other users or \emph{Incoming} 
which are words received from other users.

Based on our data set, the most commonly used words occur with a high frequency over our user base and can be seen in the table below:

\begin{table}[!htbp]
\begin{minipage}[b]{.5\textwidth}
	\centering
	\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		\textbf{Rank} & \textbf{Word} & \textbf{Frequency}  \\ \hline
		1 & :) & 292,733 \\ \hline
		2 & like & 198,289 \\ \hline
		3 & good & 164,387 \\ \hline
		4 & thanks & 159,238 \\ \hline
		5 & one & 156,696 \\ \hline
		6 & love & 139,939 \\ \hline
		7 & :p & 121,904 \\ \hline
		8 & time & 106,995 \\ \hline
		9 & think & 106,459 \\ \hline
		10 & see & 103,690 \\ \hline
		11 & nice & 99,672 \\ \hline
		12 & now & 94,947 \\ \hline
		13 & well & 92,735 \\ \hline
		14 & happy & 84,381 \\ \hline
		15 & :d & 83,698 \\ \hline
		16 & much & 78,719 \\ \hline
		17 & oh & 77,321 \\ \hline
		18 & yeah & 76,564 \\ \hline
		19 & back & 76,032 \\ \hline
		20 & great & 70,514 \\ \hline
		\end{tabular}
\end{minipage}
\begin{minipage}[b]{.5\textwidth}
\centering
\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		21 & going & 70,447 \\ \hline
		22 & still & 68,245 \\ \hline
		23 & new & 67,430 \\ \hline
		24 & day & 65,579 \\ \hline
		25 & come & 63,837 \\ \hline
		26 & ;) & 62,936 \\ \hline
		27 & year & 61,771 \\ \hline
		28 & look & 60,608 \\ \hline
		29 & yes & 59,774 \\ \hline
		30 & want & 59,514 \\ \hline
		31 & tag & 58,633 \\ \hline
		32 & hahaha & 57,448 \\ \hline
		33 & also & 56,414 \\ \hline
		34 & need & 55,921 \\ \hline
		35 & make & 54,949 \\ \hline
		36 & sure & 54,395 \\ \hline
		37 & thank & 54,112 \\ \hline
		38 & people & 53,211 \\ \hline
		39 & miss & 53,182 \\ \hline
		40 & guys & 52,855 \\ \hline
	\end{tabular}
\end{minipage}
	\caption{Top conversation content data for all users. We see very common words and online expressions have a high frequency in
	our data set.}
	\label{tab:revpol}
\end{table}

There is clearly a high number of emotional and sentimental words being used on Facebook.
This would imply interactions between real friends.

\clearpage 

WUT - scott
For messages the $I$ of our feature vector $X$ contains an element $i$ for each of the top $j$ most commonly used words based on the conversation 
content of all users.

The alters of $I$ can then be defined as all users who have liked the current item $M$.
Each component of $I$ is set to $1$ if any of the alters have used the current word $j$ where $i = j$ with the user $n$, otherwise 
it is set to $0$.

\subsection{Outgoing}
\label{sec:id}

The first issue present is to determine the most predictive number of top \emph{Outgoing} words $j$ for use by our classifiers. 
Given the enormous size of potential messages and memory constraints in the testing environment we decided to test within a range 
of $\{100-1000\}$ with an incremental step size of $100$ for each test.

The results of testing based on differing sizes of \emph{Outgoing Words} can be seen below:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/top_outgoing.pdf}
		\caption{Accuracy results for different \emph{outgoing words} sizes. Best performance can be found using LR with a small word size of only	 $200$.}
	\end{center}
\end{figure}

The most predictive \emph{Outgoing Words} words sizes $j$ for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 500
\item \textbf{Logistic Regression}: 200
\item \textbf{Support Vector Machine}: 900
\end{itemize}

Using the most predictive word sizes $j$ for each of our classifiers and building our feature vector as defined above 
we compare to our baselines and obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/bar_outgoing.pdf}
		\caption{Accuracy results using the \emph{outgoing words} features. \emph{Outgoing words} are a weaker predictor then \emph{user interactions}.}
	\end{center}
\end{figure}

These results do not show an improvement over our baselines and in fact are only a marginal improvement over the \emph{Constant} baseline. 
A possible reason for this could be due to the commonality of the words being tested. Highly common and frequently used words would 
result in poor predictive tendencies, this is eluded to in our graph above which shows an improvement in predictiveness over 
step sizes for SVM.

\clearpage

Comparing \emph{Outgoing Messages} against our exposure curve we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/line_outgoing.pdf}
		\caption{Accuracy results against exposure using the \emph{outgoing words} feature vector. \emph{Outgoing words} accuracy improve as $k$ increases, but are less predictive then \emph{user interactions}.}
	\end{center}
\end{figure}

Our exposure curve follows this similar trend of unimproved results for $k = 1$ likes, however as $k$ increases there is some improvement 
from the baselines, but this is negligible in comparison to $k = 0$ for our classifiers.

\subsection{Incoming}
\label{sec:id}

Similarly for \emph{Incoming Words} we need to discover which is the most predictive $j$ for use of by our classifiers, 
using the same methodology as described above for \emph{Outgoing Words} we obtain the following graph:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/top_incoming.pdf}
		\caption{Accuracy results for different \emph{incoming words} sizes. \emph{Incoming words} are more predictive then \emph{outgoing words}.}
	\end{center}
\end{figure}

\clearpage

The most predictive \emph{Incoming Words} words sizes $j$ for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 300
\item \textbf{Logistic Regression}: 100
\item \textbf{Support Vector Machine}: 1000
\end{itemize}

Using the most predictive word sizes $j$ for each of our classifiers as defined above and comparing to our baselines we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/bar_incoming.pdf}
		\caption{Accuracy results using the \emph{incoming words} features. \emph{Incoming words} are a weaker predictor then \emph{user interactions}.}
	\end{center}
\end{figure}

Again, \emph{Incoming Words} themselves are not predictive in comparison to our baselines, however not to the same negative
extent as \emph{Outgoing Words}.

\clearpage

Comparing \emph{Incoming Messages} against our exposure curve we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/line_incoming.pdf}
		\caption{Accuracy results against exposure using \emph{incoming words} features. \emph{Imcoming words} accuracy improve as $k$ increases, but are less predictive then \emph{user interactions}.
		}
	\end{center}
\end{figure}

For \emph{user interactions} outgoing are more important, however for \emph{words}, \emph{incoming} are more important.

Similarly, \emph{Incoming Words} improve upon our baselines as $k$ increases, however this performance increase is 
negligible in comparison with $k = 0$ and hence \emph{Incoming Words} do not prove to be predictive of user likes.

\section{Conclusion}
\label{sec:conc}

Throughout this section we have explored different avenues available for users to maintain interactions between other users. 

We have found that words, irrespective of their directionality do not assist in improving predictions. \cite{Anderson2012} concluded 
that it is less important what users say, then who they interact with, which we also found in our results, our interactions results were 
comparable to our baselines over $k = 0$ and this improvement continued over the exposure curve as our $k$ increased.

Our results have shown, that for \emph{User Interactions} it is enough for some user to have previously liked an item, which allows our 
classification methodology to offer an increase in predictiveness as $k$ increases.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 