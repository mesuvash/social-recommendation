%%
%% Template chap2.tex
%%

\chapter{User Interactions}
\label{cha:interactions}

This chapter is dedicated to analysing the different \emph{user interaction} features present in Facebook.The \emph{user interactions} we examine can be broken down into two distinct groups:
\begin{itemize}
\item \textbf{Interactions} : Posts, tags, likes and comments between users.
\item \textbf{Messages} : Both outgoing and incoming messages sent between users.
\end{itemize}

These interactions give implicit networks of friendships, previous methods \cite{www} have claimed if people interact frequently 
they will like the same things, in this section we break this idea down into the smaller implicit overlaps of these inherent interactions.

\section{Interactions}
\label{sec:inter}

Interactions between users in Facebook can be summarised under the following categories:

\begin{itemize}
\item \textbf{Direction}: Interaction directionality has been shown to be highly 
reflective of user preferences \cite{saez2011high} and can be grouped as either \emph{incoming} (for example where a message is posted to some user) or 
\emph{outgoing} (where some user posts a message to another user). 
\item \textbf{Modality}: The medium some user employs to interact with another user via either \emph{links}, \emph{posts}, \emph{photos} or \emph{videos}.
\item \textbf{Type}: The category some user employs to interact with another user via either \emph{comments}, \emph{tags} or \emph{likes}.
\end{itemize}

Some of these online \emph{interactions} suggest a real world relationship (such as being tagged in photos or videos) so we expect these to be predictive of user like preferences.

For \emph{user interactions} each feature vector $X$ where $X \in \mathbb{R}^I$ is composed of the cross product between the above components where:

\[ I = \{Incoming, Outgoing\} \times \{Posts,Photos,Videos,Links\} \times \{Comments,Tags,Likes\} \]

The alters set for each $i$ is conditioned by the relationship:

\[ Relationship_{u,i} = \{z | Interacted_{u,z,i}\} \]

In this case the $Interacted_{u,z,i}$ function returns $True$ if a user $u$ has interacted with a user $v$ via the current interaction $i$, for 
example whether user $v$ has been tagged in a photo uploaded by user $u$.

Applying this \emph{interactions} affinity feature to our classification algorithms we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/bar_interactions.pdf}
		\caption{Accuracy results using \emph{user interactions} against all data. \emph{User interactions} are less predictive then our baselines.}
	\end{center}
\end{figure}

\emph{User interactions} in themselves are not more predictive then our SMB baseline. One reason for this result could be we can 
not track information passing outside of Facebook, users who frequently interact could be real world friends and hence share 
information via email or word of mouth and not over the Facebook medium.

\clearpage

Comparing \emph{user interactions} against an exposure across $k$ we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/line_interactions.pdf}
		\caption{Accuracy results against exposure using \emph{user interaction} features. \emph{User interactions} provide a drastic improvement 
		over our baselines as $k$ increases, suggesting SMB is not always the best classifier. 
		This demonstrates the intuitive assumption that \emph{user interactions} can not improve prediction when interactions do not exist between users, while our $k$ ensures they do.
		Note in this case LR and SVM both learnt the same result.}
	\end{center}
\end{figure}

Our comparison has shown that as our data is restricted across an exposure, the performance of our classifiers improves.
This implies that for \emph{user interactions} simply having one user liking an item is enough to improve upon our baselines. 
This is intuitively correct as our classifiers can not learn when interacts do not exist between users.

\section{Conversation}
\label{sec:groups}

The next \emph{user interactions} we compare are messages passed between users. These messages can be broken down based on their 
directionality of either \emph{outgoing} (messages sent to other users) or 
\emph{incoming} (messages received from other users).

We extracted the most common words exchanged between our users, the top 40 are displayed in the table below:

\begin{table}[!htbp]
\begin{minipage}[b]{.5\textwidth}
	\centering
	\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		\textbf{Rank} & \textbf{Word} & \textbf{Frequency}  \\ \hline
		1 & :) & 292,733 \\ \hline
		2 & like & 198,289 \\ \hline
		3 & good & 164,387 \\ \hline
		4 & thanks & 159,238 \\ \hline
		5 & one & 156,696 \\ \hline
		6 & love & 139,939 \\ \hline
		7 & :p & 121,904 \\ \hline
		8 & time & 106,995 \\ \hline
		9 & think & 106,459 \\ \hline
		10 & see & 103,690 \\ \hline
		11 & nice & 99,672 \\ \hline
		12 & now & 94,947 \\ \hline
		13 & well & 92,735 \\ \hline
		14 & happy & 84,381 \\ \hline
		15 & :d & 83,698 \\ \hline
		16 & much & 78,719 \\ \hline
		17 & oh & 77,321 \\ \hline
		18 & yeah & 76,564 \\ \hline
		19 & back & 76,032 \\ \hline
		20 & great & 70,514 \\ \hline
		\end{tabular}
\end{minipage}
\begin{minipage}[b]{.5\textwidth}
\centering
\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		21 & going & 70,447 \\ \hline
		22 & still & 68,245 \\ \hline
		23 & new & 67,430 \\ \hline
		24 & day & 65,579 \\ \hline
		25 & come & 63,837 \\ \hline
		26 & ;) & 62,936 \\ \hline
		27 & year & 61,771 \\ \hline
		28 & look & 60,608 \\ \hline
		29 & yes & 59,774 \\ \hline
		30 & want & 59,514 \\ \hline
		31 & tag & 58,633 \\ \hline
		32 & hahaha & 57,448 \\ \hline
		33 & also & 56,414 \\ \hline
		34 & need & 55,921 \\ \hline
		35 & make & 54,949 \\ \hline
		36 & sure & 54,395 \\ \hline
		37 & thank & 54,112 \\ \hline
		38 & people & 53,211 \\ \hline
		39 & miss & 53,182 \\ \hline
		40 & guys & 52,855 \\ \hline
	\end{tabular}
\end{minipage}
	\caption{Top conversation content data for all users. We see very common words and online expressions have a high frequency in
	our data set. Highly emotive and sentimental words are very common, implying these interactions occur between real friends.}
	\label{tab:revpol}
\end{table}

These words show a high degree of emotion and sentiment is common between our users in words such as "thanks" and "love", 
this implies that these interactions are occurring between people who are real friends and not online associates.

For \emph{messages} each feature vector $X$ where $X \in \mathbb{R}^I$ is composed of:

For the \emph{outgoing} case:
\[ I = \{Outgoing \ Words\} \times \{Optimal \ Outgoing \ Size\} \]

For the \emph{incoming} case:
\[ I = \{Incoming \ Words\} \times \{Optimal \ Incoming \ Size\} \]

Where the optimal sizes for \emph{outgoing} and \emph{incoming} words are defined for each classifier in their corresponding sections below.

The alters set for each $i$ is conditioned by the relationship:

For the \emph{outgoing} case:
\[ Relationship_{u,i} = \{z | Messaged \ Outgoing_{u,z,i}\} \]

For the \emph{incoming} case:
\[ Relationship_{u,i} = \{z | Messaged \ Incoming_{u,z,i}\} \]

In these cases the $Messaged \ Outgoing$ and $Messaged \ Incoming$ functions return whether the user $u$ has messaged the user $z$ (outgoing) 
or whether the user $z$ has messaged the user $u$ (incoming) the word currently at index $i$ in the most popular words list (a limited version of this list is shown in \emph{Table 3.1}).

\subsection{Outgoing}
\label{sec:id}

The first issue is to determine the most predictive number of \emph{outgoing} words for use by our classifiers. 
Given the expansive size of potential messages and memory constraints in the testing environment we decided to test within a range 
of $(100-1000)$ with an incremental step size of $100$ for each test.

The results of testing based on differing sizes of \emph{outgoing} words can be seen below:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/top_outgoing.pdf}
		\caption{Accuracy results for different \emph{outgoing} words sizes. Best performance can be found using LR with a relatively small word size of only $200$ more words do not appear to increase the predictiveness for \emph{outgoing} words.}
	\end{center}
\end{figure}

\clearpage

The most predictive \emph{outgoing} words sizes for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 500.
\item \textbf{Logistic Regression}: 200.
\item \textbf{Support Vector Machine}: 900.
\end{itemize}

Using these most predictive word sizes for each of our classifiers and building our feature vector as defined above we obtain the following results:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/bar_outgoing.pdf}
		\caption{Accuracy results using \emph{outgoing} words. \emph{Outgoing} words are clearly less predictive then both our baseline and \emph{user interactions}.}
	\end{center}
\end{figure}

These results do not show an improvement over our \emph{interactions} or our baselines and are only a marginal improvement over the \emph{constant} baseline. 
Demonstrating that \emph{outgoing words} are not predictive of a users like preferences.

A possible reason for this could be due to the commonality of the words being tested. Highly common and frequently used words could 
result in poor predictive performance.

\clearpage

Comparing \emph{outgoing} words against exposure we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/line_outgoing.pdf}
		\caption{Accuracy results against exposure using the \emph{outgoing} words feature. \emph{Outgoing} words predictiveness improve as $k$ increases, but this feature is less predictive
				 even in the case for $k=3$ when compared with SMB when $k=0$.}
	\end{center}
\end{figure}

The exposure offers an increase in the predictiveness of the \emph{outgoing} words feature. However even when $k=3$, this feature still does 
not outperform SMB when $k=0$. Indicating that \emph{outgoing} words are not a useful feature for prediction.

\subsection{Incoming}
\label{sec:id}

Similarly for \emph{incoming} words we need to discover the most predictive word size for use by our classifiers, 
using the same methodology as described above for \emph{outgoing} words we obtain the following graph:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/top_incoming.pdf}
		\caption{Accuracy results for different \emph{incoming} words sizes. \emph{Incoming} words are more predictive then \emph{outgoing} words, but follow
				 the similar trend that relatively small sizes offer close to optimal predictions for this feature.}
	\end{center}
\end{figure}

\clearpage

The most predictive \emph{incoming} words sizes for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 300.
\item \textbf{Logistic Regression}: 100.
\item \textbf{Support Vector Machine}: 1000.
\end{itemize}

Using these most predictive word sizes for each of our classifiers we obtain the following results:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/bar_incoming.pdf}
		\caption{Accuracy results using the \emph{incoming} words features. \emph{Incoming} words are a 
				 stronger predictor then \emph{outgoing} words implying \emph{incoming} words are more predictive, however they are still a weaker predictor then \emph{user interactions} and our baselines.}
	\end{center}
\end{figure}

\emph{Incoming} words are more predictive then \emph{outgoing} words, however \emph{incoming} words themselves are not more predictive then our baselines.
Comparing \emph{incoming} words against exposure we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/line_incoming.pdf}
		\caption{Accuracy results against exposure using \emph{incoming} words features. 
				 \emph{Incoming} words predictions improve as $k$ increases and outperform SMB, however they are still less predictive then \emph{user interactions}.
		}
	\end{center}
\end{figure}

\clearpage

\emph{Incoming} words improve upon our baselines as $k$ increases, however this predictive increase is 
negligible in comparison with SMB when $k = 0$ and \emph{user interactions} across $k=2$ and $k=3$ and 
hence \emph{incoming} words are not predictive of user likes.

\emph{Incoming} words show an improvement over \emph{outgoing} words, however neither outperforms \emph{user interactions}.

\section{Conclusion}
\label{sec:conc}

Throughout this chapter we have explored the different interaction types available between users on Facebook. 

We have found that words, irrespective of their directionality do not assist in improving predictions. \cite{Anderson2012} concluded 
that it is less important what users say, then who they interact with, which we also found in our results. Additionally, it has been shown
for \emph{user interactions} \emph{outgoing} interactions are more important then \emph{incoming} \cite{www}, while our results have found that
for words, \emph{incoming} are more important then \emph{outgoing}. Overall, \emph{messages} are a much weaker at prediction compared 
with both \emph{interactions} and our baselines.

Our results have shown, that for \emph{interactions} to improve upon our baseline predictions it is enough for some user to 
have previously liked the item, this allows an improvement in predictiveness as $k$ increases because there are at least $k$ users for each item
which our predictors can learn from.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 