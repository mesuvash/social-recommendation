%%
%% Template intro.tex
%%

\chapter{Background}
\label{cha:back}

\section{Social Networks}
\label{sec:sn}

The social network central for this study is Facebook. Once registering, Facebook users have the option of setting up a personalised profile, they can then establish
 themselves as friends of other users. Friends can interact via wall posts, conversations or by liking some facebook element.

Social networks such as Facebook provide a wide array of user preferences (link, tag, photo, video likes) in an array of interaction mediums and modalities 
(outgoing, incoming) as well as user specific information (gender, age, location, group memberships, favorite movies) and conversation content.

A problem with the Facebook paradigm in relation to this analysis is the requirement for assumed dislikes, if a user does not like some link can we 
imply the user does not like this link? Given the time period Facebook shows a link and the differing online times for Facebook users, this is generally 
a poor assumption. As such a Facebook app named LinkR was developed by NICTA which explicitly stores like and dislike data for users. This app will 
be discussed in the following section.

\section{Data Set}
\label{sec:data}

The LinkR Facebook app was used to collect information about users, their interactions and preferences. The data set contains information about app users as 
well as a sub-set of visible information about their friends. The app tracked and stored information for over 100 app users and their 39,000+ friends.

The four main interactions between users are posts (posting an element on a friends' wall), tags (being mentioned in a friends post or comment), 
 comments (written data on a post) and likes (clicking a like button if a user likes a post or comment). The table below outlines data collected during 
 app trials.

\begin{table}[!htbp]
\centering
	\begin{tabular}{|l|r|r|r|r|} % cols: (left, center, right)
		\hline
		\textbf{App Users} & \textbf{Posts} & \textbf{Tags} & \textbf{Comments} & \textbf{Likes}  \\ \hline
		\textbf{Wall} & 27,955 & 5,256 & 15,121 & 11,033 \\ \hline
		\textbf{Link} & 3,974 & - & 5,757 & 4,279 \\ \hline
		\textbf{Photo} & 4,147 & 22,633 & 8,677 & 5,938 \\ \hline
		\textbf{Video} & 211 & 2,105 & 1,687 & 710 \\ \hline
		 \hline
		\textbf{App Users and Friends} & \textbf{Posts} & \textbf{Tags} & \textbf{Comments} & \textbf{Likes}  \\ \hline
		\textbf{Wall} & 3,384,740 & 912,687 & 2,152,321 & 1,555,225 \\ \hline
		\textbf{Link} & 514,475 & - & 693,930 & 666,631 \\ \hline
		\textbf{Photo} & 1,098,679 & 8,407,822 & 2,978,635 & 1,960,138 \\ \hline
		\textbf{Video} & 56,241 & 858,054 & 463,401 & 308,763 \\ \hline
	\end{tabular}
	\caption{Total app user records}
	\label{tab:revpol}
\end{table}

\clearpage

\section{Notation}
\label{sec:notation}

The mathematical notation used by our Predictors during this thesis are outlined below.

\begin{itemize}
\item A dataset $D$ comprised of $N$ user feature vectors $x$ of size $I$, where each element $x_i \in \{0,1\}$

\item The feature size of $I$ for each $x$ is defined by the current feature set being tested.

\item A mapping for each tested vector $N$ from $D$ of the form $x \to y$ where $y$ is the prediction for this feature vector of the form
$y \in \{0 \;\mbox{(like)},1 \;\mbox{(dislike)}\}$ based on each element in $x_i$

\end{itemize}

\section{Feature Sets}
\label{sec:features}

The feature sets in $x$ can be any of the following, which are discussed further in :::

\begin{itemize}
\item Interactions
\item Demographics
\item Traits
\item Groups
\item Pages
\item Outgoing Messages
\item Incoming Messages
\end{itemize}

\section{Previous Work}
\label{sec:pw}

\subsection{Content Based Filtering}
\label{sec:cbf}

\subsection{Information Diffusion}
\label{sec:id}

\section{Prediction Algorithms}
\label{sec:meth}

This analysis makes use of the results from a number of different prediction algorithms which are outlined below.

\subsection{Constant}
\label{sec:const}

The constant predictor returns a constant result irrespective of the feature vectors selected from above. The most common result in our data
set is $False$ and hence the $False$ predictor is used in our analysis.

\subsection{Social Recommender}
\label{sec:sr}

\subsection{Naive Bayes}
\label{sec:nb}

\emph{Naive Bayes} (NB) is a basic predictor which involves applying Bayes' theorem using independence assumptions between each feature in $x$.

The NB implementation used during this thesis is an implementation previously devised by \emph{Scott Sanner} \cite{scott}.

\subsection{Logistic Regression}
\label{sec:lr}

\emph{Logistic Regression} (LR) predicts the odds of being either a like or a dislike by converting a dependent variable and one or more continuous 
independent variable(s) into probabability odds.

The LR implementation used during this thesis is \emph{LingPipe} \cite{lin}, which supports:
\begin{itemize}
\item Three priors for regression (Cauchy, Gaussian, Laplace)
\item Maximum entropy mode
\end{itemize}

\subsection{Support Vector Machine}
\label{sec:svm}

The \emph{Support Vector Machine} (SVM) is a supervised learning machine based on a set of basis functions which help construct a separating 
hyperplane between the data points. Training involves buidling the relevant hyperplanes which can then be used for testing. Each data point is
classified depending on which side of the hyperplane it falls.

The SVM implementation used during this thesis is \emph{SVMLibLinear} \cite{cjlin}, which supports:
\begin{itemize}
\item L2-regularized classifiers
\item L2-loss linear SVM, L1-loss linear SVM, and logistic regression (LR)
\item L1-regularized classifiers
\item L2-loss linear SVM and logistic regression (LR)
\item L2-regularized support vector regression
\item L2-loss linear SVR and L1-loss linear SVR.
\item Probability estimates
\end{itemize}

\section{Training and Testing}
\label{sec:tt}

All evaluation is done using 10 fold cross validation wherein the data is partitioned into 10 complimentary subsets, each subset is composed 
of two separate parts one section is used for training $(80\%)$ and the other $(20\%)$ is used for testing. This is performed on 10 distinct 
subsets and the results are averaged across each fold.

\section{Evaluation Metrics}
\label{sec:notation}

When evaluating the success of each method at correctly predicting the classification, the following metrics will be used.

\begin{itemize}
\item A \emph{true positive} prediction refers to when the classifier correctly identifies the class as true. 
\item A \emph{false positive} occurs when the prediction is true, but the true class was false. 
\item A \emph{false negative} occurs when the prediction is false but the actual class is true.
\end{itemize}

Accuracy relates to the closeness of the true value. In the context of our results, the accuracy refers to the number of correct classifications 
divided by the size of the data set.

\[
 \text{accuracy} = \frac{\text{number of correct classifications}}{\text{size of the test data set}}
\]

Precision relates to the number of retrieved predictions which are relevant. In the context of our results, the precision refers to the number of true positive predictions 
divided by the sum of the true positive and false positive predictions.

\[
 \text{precision} = \frac{\text{number of true positives}}{\text{number of true positives + number of false positives}}
\]

Recall refers to the number of relevant predictions that are retrieved. In the context of our results, recall refers to the number of true positive predictions 
divided by the sum of the true positive and false negative predicitons.

\[
 \text{recall} = \frac{\text{number of true positives}}{\text{number of true positives + number of false negatives}}
\]

The f-score combines and balances both precision and recall and is refered to as the weighted average of both precision and recall. 

\[
 \text{f-score} = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}
\]

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
