%%
%% Template chap2.tex
%%

\chapter{User Interactions}
\label{cha:interactions}

This chapter is dedicated to analysing the different \emph{user interaction} features present in Facebook.

The \emph{user interactions} we examine in this thesis can be broken down into two distinct groups:
\begin{itemize}
\item \textbf{Interactions} : Posts, Tags, Likes, Comments between users.
\item \textbf{Messages} : Both outgoing and incoming messages sent between users.
\end{itemize}

These interactions give implicit networks of friendships, previous methods \cite{www} have claimed if people interact frequently 
they will like the same things, in this section we break this idea down into the smaller implicit overlaps of these interactions.

\section{Interactions}
\label{sec:inter}

Interactions between users in Facebook can be summarised under the following categories:

\begin{itemize}
\item \textbf{Direction}: The manner an interaction is received, either \emph{incoming} for example where a message is posted to some user or 
\emph{outgoing} where some user posts a message to another user. Interaction directionality has been shown to be highly 
reflective of user preferences \cite{saez2011high}.
\item \textbf{Modality}: The medium some user employs to interact with another user via either \emph{links}, \emph{posts}, \emph{photos} or \emph{videos}.
\item \textbf{Type}: The style some user employs to interact with another user via either \emph{comments}, \emph{tags} or \emph{likes}.
\end{itemize}

For \emph{user interactions} each user $u$ and feature vector $x$ is defined as the cross product of the above components where:

\[ I = \{Incoming, Outgoing\} \times \{Posts,Photos,Videos,Links\} \times \{Comments,Tags,Likes\} \]

The alters set for each $i$ is conditioned by the relationship $R$, where:

\[ R_{i,u} = \{z | Interacted_{i,u,z}\} \]

In this case the $Interacted$ function returns all users $z$ who have interacted with user $u$ via the current interaction $i$.

Applying this affinity feature to our classification algorithms we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/bar_interactions.pdf}
		\caption{Accuracy results using \emph{user interactions} against all data. \emph{User interactions} do not outperform our baselines.}
	\end{center}
\end{figure}

\emph{User interactions} in themselves are not more predictive then our SMB baseline. One reason for this result could be we can 
not track information passing outside of Facebook, users who frequently interact could be real world friends and hence share 
information via email or word of mouth and not over Facebook.

\clearpage

Comparing \emph{user interactions} against an exposure across $k$ we obtain:

\begin{figure}[tbh!]
	\begin{center}
		\includegraphics[scale=0.75]{results/interactions/line_interactions.pdf}
		\caption{Accuracy results against exposure using \emph{user interaction} features. \emph{User interactions} provide a drastic improvement 
		over our baselines as $k$ increases, suggesting SMB is not always the best classifier. 
		This demonstrates the intuitive assumption that \emph{user interactions} can not improve prediction when these interactions do not exist between users.
		Note in this case LR and SVM both learnt the same result.}
	\end{center}
\end{figure}

Our comparison has shown that as our data is restricted across an exposure, the performance of our classifiers improves.
This implies that for \emph{user interactions} simply having one user liking an item is enough to improve upon our baselines. 
This is intuitively correct as our classifiers can not learn when interacts do not exist between users.

\section{Conversation}
\label{sec:groups}

The next \emph{user interactions} we compare are messages passed between users.

These messages can be broken down based on their directionality, either \emph{outgoing} which are messages sent to other users or 
\emph{incoming} which are messages received from other users.

Based on our data set, the most common words occur with a high frequency and are outlined in the table below:

\begin{table}[!htbp]
\begin{minipage}[b]{.5\textwidth}
	\centering
	\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		\textbf{Rank} & \textbf{Word} & \textbf{Frequency}  \\ \hline
		1 & :) & 292,733 \\ \hline
		2 & like & 198,289 \\ \hline
		3 & good & 164,387 \\ \hline
		4 & thanks & 159,238 \\ \hline
		5 & one & 156,696 \\ \hline
		6 & love & 139,939 \\ \hline
		7 & :p & 121,904 \\ \hline
		8 & time & 106,995 \\ \hline
		9 & think & 106,459 \\ \hline
		10 & see & 103,690 \\ \hline
		11 & nice & 99,672 \\ \hline
		12 & now & 94,947 \\ \hline
		13 & well & 92,735 \\ \hline
		14 & happy & 84,381 \\ \hline
		15 & :d & 83,698 \\ \hline
		16 & much & 78,719 \\ \hline
		17 & oh & 77,321 \\ \hline
		18 & yeah & 76,564 \\ \hline
		19 & back & 76,032 \\ \hline
		20 & great & 70,514 \\ \hline
		\end{tabular}
\end{minipage}
\begin{minipage}[b]{.5\textwidth}
\centering
\begin{tabular}{|c|c|c|} % cols: (left, center, right)
		\hline
		21 & going & 70,447 \\ \hline
		22 & still & 68,245 \\ \hline
		23 & new & 67,430 \\ \hline
		24 & day & 65,579 \\ \hline
		25 & come & 63,837 \\ \hline
		26 & ;) & 62,936 \\ \hline
		27 & year & 61,771 \\ \hline
		28 & look & 60,608 \\ \hline
		29 & yes & 59,774 \\ \hline
		30 & want & 59,514 \\ \hline
		31 & tag & 58,633 \\ \hline
		32 & hahaha & 57,448 \\ \hline
		33 & also & 56,414 \\ \hline
		34 & need & 55,921 \\ \hline
		35 & make & 54,949 \\ \hline
		36 & sure & 54,395 \\ \hline
		37 & thank & 54,112 \\ \hline
		38 & people & 53,211 \\ \hline
		39 & miss & 53,182 \\ \hline
		40 & guys & 52,855 \\ \hline
	\end{tabular}
\end{minipage}
	\caption{Top conversation content data for all users. We see very common words and online expressions have a high frequency in
	our data set. Additionally highly emotive and sentimental words are very common, implying these interactions occur between \emph{real} friends.}
	\label{tab:revpol}
\end{table}

For messages each user $u$ and feature vector $x$ is defined as the cross product of:

\[ I = \{Incoming, Outgoing\} \times \{Messages Size\} \]

Where the optimal \emph{messages size} $J$ is defined for each directionality and classifier.

The alters set for each $i$ is conditioned by the relationship $R$, where:

\[ R_{i,u} = \{z | Messaged_{i,u,z,j}\} \]

In this case the $Messaged$ function returns all users $z$ who have messaged user $u$ via the current messaging direction $i$ with the
word at index $j$.

\subsection{Outgoing}
\label{sec:id}

The first issue is to determine the most predictive number of \emph{outgoing} words $j$ for use by our classifiers. 
Given the expansive size of potential messages and memory constraints in the testing environment we decided to test within a range 
of $\{100-1000\}$ with an incremental step size of $100$ for each test.

The results of testing based on differing sizes of \emph{outgoing} words can be seen below:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/top_outgoing.pdf}
		\caption{Accuracy results for different \emph{outgoing} words sizes. Best performance can be found using LR with a relatively small word size of only $200$.}
	\end{center}
\end{figure}

The most predictive \emph{outgoing} words sizes $j$ for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 500
\item \textbf{Logistic Regression}: 200
\item \textbf{Support Vector Machine}: 900
\end{itemize}

Using the most predictive word sizes $j$ for each of our classifiers and building our feature vector as defined above we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/bar_outgoing.pdf}
		\caption{Accuracy results using the \emph{outgoing} words features. \emph{Outgoing} words are clearly less predictive then \emph{user interactions}.}
	\end{center}
\end{figure}

These results do not show an improvement over our baselines and are only a marginal improvement over the \emph{constant} baseline. 

A possible reason for this could be due to the commonality of the words being tested. Highly common and frequently used words would 
result in poor predictive tendencies.

\clearpage

Comparing \emph{outgoing} words against exposure we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/outgoing/line_outgoing.pdf}
		\caption{Accuracy results against exposure using the \emph{outgoing} words feature. \emph{Outgoing} words predictiveness improve as $k$ increases, but are still less predictive
				 even in the case for $k=3$ when compared with SMB when $k=0$.}
	\end{center}
\end{figure}

The exposure offers an increase in the predictiveness of the \emph{outgoing} words feature. However even when $k=3$, this feature does 
not outperform SMB when $k=0$. Indicating that \emph{outgoing} words are not a predictive feature in our data set.

\subsection{Incoming}
\label{sec:id}

Similarly for \emph{incoming} words we need to discover which is the most predictive word size $j$ for use by our classifiers, 
using the same methodology as described above for \emph{outgoing} words we obtain the following graph:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/top_incoming.pdf}
		\caption{Accuracy results for different \emph{incoming} words sizes. \emph{Incoming} words are more predictive then \emph{outgoing} words, but follow
				 the similar trend that small sizes offer close to optimal predictions for this feature.}
	\end{center}
\end{figure}

The most predictive \emph{incoming} words sizes $j$ for each of our classifiers are:
\begin{itemize}
\item \textbf{Naive Bayes}: 300
\item \textbf{Logistic Regression}: 100
\item \textbf{Support Vector Machine}: 1000
\end{itemize}

\clearpage

Using these most predictive word sizes for each of our classifiers we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/bar_incoming.pdf}
		\caption{Accuracy results using the \emph{incoming} words features. \emph{Incoming} words are a 
				 stronger predictor then \emph{outgoing} words, however they are still a weaker predictor then \emph{user interactions}.}
	\end{center}
\end{figure}

Similarly to \emph{outgoing} words, \emph{incoming} words themselves are not more predictive in comparison to our baselines.

Comparing \emph{incoming} words against exposure we obtain:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.75]{results/incoming/line_incoming.pdf}
		\caption{Accuracy results against exposure using \emph{incoming} words features. 
				 \emph{Incoming} words predictive accuracy improves as $k$ increases, but are still less predictive then \emph{user interactions}.
		}
	\end{center}
\end{figure}

Similarly, \emph{incoming} words improve upon our baselines as $k$ increases, however this predictive increase is 
negligible in comparison with $k = 0$ and hence \emph{incoming} words are not predictive of user likes.

\emph{Incoming} words show an improvement over \emph{outgoing} words, however neither outperforms \emph{user interactions}.

\section{Conclusion}
\label{sec:conc}

Throughout this chapter we have explored the different interaction types available between users on Facebook. 

We have found that words, irrespective of their directionality do not assist in improving predictions. \cite{Anderson2012} concluded 
that it is less important what users say, then who they interact with, which we also found in our results. Additionally, it has been shown
for \emph{user interactions} outgoing interactions are more important \cite{www}, while our results have found that
for \emph{words}, \emph{incoming} are more important.

Our results have shown, that for \emph{user interactions} to improve upon baseline prediction it is enough for some user to 
have previously liked the item, this allows our classification methodology to improve predictiveness as $k$ increases because 
interactions exist between these users and our classifiers can learn from them.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 